# 생성형 AI와 ChatGPT의 작동 원리  
## ― ChatGPT Agent System Card 분석

본 문서는 OpenAI가 공개한 **ChatGPT Agent System Card**를 바탕으로  
생성형 AI와 ChatGPT, 특히 **에이전트형(ChatGPT Agent)** 모델의 작동 원리와  
안전 설계 철학을 기술적 관점에서 정리한 자료입니다.

---

## 1. 시스템 카드가 말하는 “ChatGPT 에이전트”의 정체

시스템 카드는 ChatGPT 에이전트를 **OpenAI o3 계열의 에이전트형 모델**로 설명하며,  
다음 요소들을 **하나의 시스템**으로 결합했다고 요약합니다.

- **Deep research**  
  여러 단계를 거쳐 정보를 조사하고 구조화된 보고서를 생성

- **Operator**  
  원격 *비주얼 브라우저*를 통해 웹사이트에서 실제 작업 수행

- **Terminal tool**  
  코드 실행, 데이터 분석(제한적 네트워크), 슬라이드·스프레드시트 생성

- **Connectors**  
  Google Drive와 같은 외부 데이터 및 애플리케이션 연동

즉, ChatGPT 에이전트는 단순히 “말을 잘하는 챗봇”이 아니라,

> **(1) 추론·계획 → (2) 도구 선택·행동 → (3) 결과물 생성**

까지를 하나로 묶은 **통합 에이전트 시스템**입니다.

---

## 2. 생성형 AI(LLM)의 기본 작동 원리  
### “다음 토큰 예측”이 전부인가?

기본적으로 ChatGPT와 같은 LLM은  
입력된 대화 맥락(Context)을 바탕으로 **다음에 올 텍스트 토큰을 확률적으로 예측**해  
문장을 생성합니다.

하지만 **에이전트형 AI**로 확장되면, 예측 대상은 단순한 텍스트를 넘어섭니다.

예를 들어 다음과 같은 판단까지 포함됩니다.

- “지금은 검색이 필요하다”
- “브라우저로 사이트에 접속해 클릭해야 한다”
- “터미널에서 데이터를 계산해 표를 만들어야 한다”
- “이 단계에서는 사용자 확인을 받아야 한다”

즉, **행동(툴 호출) 시퀀스 자체가 예측 대상**이 됩니다.

시스템 카드가 강조하는 핵심 포인트는 다음과 같습니다.

> ChatGPT 에이전트는  
> 브라우저·터미널·커넥터 등 **더 많은 도구에 동시에 접근**하기 때문에  
> 기존 챗봇보다 **행동 리스크가 커졌고**,  
> 이를 전제로 한 **별도의 안전 설계가 필수**라는 점입니다.

---

## 3. “에이전트”가 되면서 생기는 핵심 메커니즘  
### 계획 → 실행 → 검증 (Plan → Act → Verify)

시스템 카드의 기능 설명을 **작동 루프**로 재구성하면 다음과 같습니다.

---

### A. 목표 이해 및 계획 (Plan)

- 사용자 요청을 **목표와 하위 작업**으로 분해
- 각 단계가 “조사”인지 “실행(액션)”인지 구분
- Deep research를 통해 다단계 조사 및 보고서 작성 수행

---

### B. 도구 선택 및 실행 (Act)

작업 성격에 따라 도구를 선택합니다.

- 웹 상호작용 → **원격 비주얼 브라우저**
- 계산·분석·산출물 생성 → **터미널 도구**
  - 단, 네트워크 접근은 제한됨
- 사용자 데이터 접근 → **커넥터**
  - 예: 드라이브, 이메일 등

---

### C. 사용자 통제 및 검증 (Verify)

- 구매 완료, 이메일 발송 등  
  **“세상 상태를 바꾸는 행동”**에 대해서는
  반드시 **사용자 확인(User confirmation)**을 요구하도록 훈련됨

이 세 단계가 반복되면서,  
ChatGPT 에이전트는 **“끝까지 일을 처리하는 시스템”**으로 진화합니다.

---

## 4. 시스템 카드의 핵심 메시지  
### 안전 설계를 ‘기능’만큼 크게 다룸

이 문서의 절반 이상은 사실상  
**“에이전트가 위험해질 수 있는 지점”과 “그에 대한 완화책”**에 할애되어 있습니다.

---

### 4-1. 프롬프트 인젝션을 ‘가장 큰 제품 리스크’로 취급

시스템 카드는 **프롬프트 인젝션(prompt injection)**을 다음과 같이 정의합니다.

> 웹페이지나 문서 등에 숨겨진 악성 지시문이  
> 에이전트의 행동을 가로채  
> 데이터 유출이나 의도치 않은 행동을 유발하는 공격

이를 방지하기 위해 **다층 방어(Multi-layered mitigations)** 전략을 설계했다고 밝힙니다.

대표적인 완화책은 다음과 같습니다.

- 프롬프트 인젝션 **강건성 안전 훈련**
- 자동 모니터 및 필터 (신규 공격에 신속 대응)
- **사용자 확인(Confirmation)**
- 민감 맥락에서의 **Watch Mode**
  - 사용자가 자리를 비우면 자동 중지
- 터미널 **네트워크 제한**
- **메모리 비활성화**
  - 데이터 유출 시도 감소 목적

요약하면,

> **모델이 똑똑해질수록 인젝션에 더 취약해질 수 있으므로  
> 훈련 + 필터 + 사용자 감독 + 권한 제한을 겹겹이 둔다**

라는 설계 철학입니다.

---

### 4-2. “에이전트의 실수”를 별도 위험군으로 정의

시스템 카드는 다음을 명확히 구분합니다.

- 단순 환각(Hallucination)
- 실제 행동에서 발생하는 **에이전트의 실수(Action error)**

예:
- 잘못된 대상에게 이메일 발송
- 잘못된 구매 실행

이를 줄이기 위해 **확인 절차 강화**를 핵심 대책으로 제시합니다.

---

### 4-3. 유해·금지 작업 요청에 대한 정책 강화

에이전트가 수행해서는 안 되는 범위를 명확히 규정합니다.

- 사생활 침해 가능성이 큰 개인 데이터 수집·추론
- 규제 상품 거래, 도박
- 금융 계좌 이체 등 고위험 금융 행동 지원

---

## 5. 평가(Eval)가 보여주는 관점 변화  
### “정확도”보다 “안전한 행동”

시스템 카드는 기존 LLM 평가 외에  
**에이전트형 모델 전용 평가 항목**을 포함합니다.

- 프롬프트 인젝션 관련 평가
  - 시스템 프롬프트 추출
  - 인젝션 하이재킹
- 환각 평가
  - SimpleQA, PersonQA 등
- **사용자 확인(Confirmation) 리콜**
  - 확인을 요구해야 할 때 제대로 요구하는지 평가

이는 다음 관점 변화를 보여줍니다.

> 생성형 AI의 품질은  
> 단순히 “그럴듯한 답변”이 아니라  
> **언제 멈추고, 언제 물어보는가**까지 포함한다.

---

## 6. 준비성 프레임워크(Preparedness Framework) 관점

OpenAI는 이번 ChatGPT 에이전트 출시를  
생물·화학(Bio/Chem) 영역에서 **High capability**로 분류하고  
해당 안전장치를 **예방적으로 활성화**했다고 설명합니다.

이는,

- 모델이 직접 위험 정보를 생성했는지 여부보다
- **도구 결합으로 인해 능력이 커졌을 때의 잠재 리스크**

까지 포함해 **보수적으로 관리**하겠다는 접근입니다.

---

## 7. 결론: 한 줄 요약

> **ChatGPT 에이전트 =  
> (언어모델의 추론·계획)  
> + (브라우저·터미널·커넥터 도구 실행)  
> + (사용자 통제 기반 안전장치)로 구성된  
> 통합 에이전틱 시스템**

특히 프롬프트 인젝션, 행동 실수, 금지 행동을 전제로  
**다층 안전 설계를 시스템 레벨에서 강하게 적용했다**는 점이  
이 시스템 카드의 핵심 메시지입니다.

---

### 작성 목적
- 기술 블로그 게시
- GitHub 문서화
- AI Agent / 보안 / IAM 관점 이해를 위한 참고 자료
