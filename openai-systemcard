1) 시스템 카드가 말하는 “ChatGPT 에이전트”의 정체

시스템 카드는 ChatGPT 에이전트를 OpenAI o3 계열의 에이전트형 모델로 설명하면서, 다음을 “한 시스템”으로 결합했다고 요약합니다.

Deep research: 여러 단계를 거쳐 조사하고 보고서를 생성

Operator: 원격 “비주얼 브라우저”로 웹사이트에서 실제 작업 수행

Terminal tool: 코드 실행·데이터 분석(제한적 네트워크)·슬라이드/스프레드시트 생성

Connectors: Google Drive 같은 외부 데이터/앱 연결

즉, “말만 잘하는 챗봇”이 아니라 (1) 추론/계획 + (2) 도구선택/행동 + (3) 결과물 생성까지 묶은 형태입니다.

2) 생성형 AI(LLM)의 기본 작동원리: “다음 토큰 예측”이 전부인가?

기본적으로 ChatGPT 같은 LLM은 입력(대화 맥락)을 보고 다음에 올 텍스트 조각(토큰)을 확률적으로 예측해 문장을 만듭니다.
다만 “에이전트형”으로 가면, 그 예측 대상이 단순 답변 텍스트를 넘어서:

“지금은 검색해야겠다”

“브라우저로 사이트에 들어가 클릭해야겠다”

“터미널로 데이터를 계산해 표를 만들어야겠다”

“사용자 확인을 받아야겠다”

같은 행동(툴 호출) 시퀀스까지 포함됩니다.

시스템 카드가 강조하는 포인트는, ChatGPT 에이전트가 동시에 더 많은 도구에 접근하기 때문에(브라우저+터미널+커넥터) 기존 챗봇보다 ‘행동 리스크’가 커져서 별도 안전 설계가 필요해졌다는 점입니다.

3) “에이전트”가 되면서 생기는 핵심 메커니즘: 계획 → 실행 → 검증 루프

시스템 카드의 기능 설명을 ‘작동 루프’로 재구성하면 대략 이렇습니다.

A. 목표 이해 및 계획(Plan)

사용자 요청을 목표/하위작업으로 쪼개고, 어떤 단계가 “조사”이고 어떤 단계가 “실행(액션)”인지 분리합니다.
Deep research를 통해 다단계 조사·보고서 작성이 가능하다고 밝힙니다.

B. 도구 선택 및 실행(Act)

작업 성격에 따라:

웹 상호작용은 원격 비주얼 브라우저로 수행

계산/분석/산출물 생성은 터미널 도구를 사용(단, 네트워크는 제한)

사용자 데이터 접근은 커넥터로 수행(예: 드라이브/이메일)

C. 사용자 통제/검증(Verify)

특히 “세상 상태를 바꾸는 행동”(구매 완료, 이메일 발송 등)은 **사용자 확인(User confirmation)**을 요구하도록 훈련했다고 명시합니다.

이 3단계가 반복되면서 “끝까지 일을 처리”하는 쪽으로 진화합니다.

4) 시스템 카드의 핵심: 안전 설계를 ‘기능’만큼 크게 다룸

이 문서의 절반 이상은 사실상 **“에이전트가 위험해질 수 있는 지점”과 “완화책”**입니다.

4-1) 프롬프트 인젝션(prompt injection)을 ‘가장 큰 제품 리스크’로 취급

시스템 카드는 프롬프트 인젝션을
“웹페이지 등에 숨겨진 악성 지시문이 에이전트의 행동을 가로채 데이터 유출/의도치 않은 행동을 유발할 수 있는 공격”으로 정의합니다.

그리고 **다층 방어(multi-layered mitigations)**를 설계했다고 밝히며, 대표적으로:

프롬프트 인젝션 강건성 안전 훈련

자동 모니터/필터(새 공격에 빠르게 업데이트 가능)

사용자 확인(confirmation)

민감 맥락에서 Watch Mode(사용자가 자리 비우면 자동 중지 등 “감시/감독” 요구)

터미널 네트워크 제한(예: launch 시점엔 특정 형태의 GET 다운로드 등 추가 제한)

메모리 비활성화(메모리에서 데이터 유출 시도를 줄이기 위해 launch 시점에 메모리 끔)

요약하면: “모델이 똑똑해질수록 인젝션에 더 취약해질 수 있으니, 훈련+필터+사용자감독+권한제한을 겹겹이 둔다”는 설계 철학입니다.

4-2) “에이전트의 실수”를 별도 위험군으로 정의

단순 환각(hallucination)뿐 아니라, 실제 구매/발송 같은 행동에서의 실수를 문제로 분리하고, 이를 줄이기 위해 확인 절차를 강조합니다.

4-3) “유해/금지 작업 요청”에 대한 정책 강화

시스템 카드는 에이전트가 해서는 안 되는 범위를 구체적으로 언급합니다. 예를 들면:

사생활 기대가 큰 개인 데이터 “수집/추론”을 위한 온라인 리서치 금지

규제 상품 거래, 도박 등 금지

금융 계좌 이체 같은 고위험 금융 행동 지원 금지

5) 평가(Eval)를 통해 드러나는 작동 특성: “정확도”보다 “안전한 행동”을 측정하려고 함

시스템 카드는 전통적인 유해콘텐츠/탈옥/환각 같은 평가 외에도, 에이전트형 특성에 맞춘 평가를 넣습니다.

프롬프트 인젝션 관련: “시스템 프롬프트 추출”, “인젝션 하이재킹” 같은 평가 항목을 별도로 다룸

환각 평가: SimpleQA/PersonQA 등에서 정확도 및 환각률을 제시(브라우징 포함 비교 언급)

“확인(confirmation) 리콜”처럼, 사용자 확인을 제대로 요구하는지를 평가

이건 “생성형 AI의 품질 = 그럴듯한 답변”이 아니라, ‘행동하는 모델’은 ‘멈추고 물어보기/감시모드/권한 제한’ 같은 안전동작이 품질의 일부라는 관점이 강하게 반영된 겁니다.

6) 준비성 프레임워크(Preparedness Framework) 관점: “예방적” 고위험 분류

한국어 소개 페이지와 PDF 모두에서, OpenAI는 이번 출시를 생물·화학(Bio/Chem) 영역에서 ‘High capability’로 취급해 해당 안전장치를 활성화한다고 밝힙니다(명확한 증거가 없더라도 예방적으로).

이는 “모델이 직접 위험 정보를 만들었느냐”보다, 도구 결합으로 능력이 커졌을 때의 잠재 리스크까지 포함해 보수적으로 다루겠다는 신호로 읽힙니다.

7) 결론: 이 시스템 카드가 보여주는 생성형 AI/ChatGPT의 ‘작동원리’ 한 줄 요약

**ChatGPT 에이전트 = (언어모델의 추론/계획) + (브라우저/터미널/커넥터 도구 실행) + (사용자 통제 기반 안전장치)로 구성된 “통합 에이전틱 시스템”**이며, 특히 프롬프트 인젝션·실수·금지행동을 전제로 다층 안전 설계를 시스템 레벨에서 강하게 넣었다—가 이 문서의 핵심 메시지입니다.
